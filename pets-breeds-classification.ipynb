{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870609df",
   "metadata": {},
   "source": [
    "# Pets Breeds Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1f421",
   "metadata": {},
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104b649",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "Datased used for this code title is 'The Oxford-IIIT Pet Dataset' containing photos of 37 different breeds of cats and dogs with roughly 200 images for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\"\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad463fc",
   "metadata": {},
   "source": [
    "The downloaded dataset should contain 7,390 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*.jpg')))\n",
    "print(str(image_count) + \" images successfully downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07106c9a",
   "metadata": {},
   "source": [
    "Example of an image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(data_dir.glob('*.jpg'))\n",
    "PIL.Image.open(str(images[500]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd108364",
   "metadata": {},
   "source": [
    "## Load dataset to a TensorFlow dataset object\n",
    "\n",
    "So far the dataset is just a set of photos in a folder. In order to train a model, a *tf.data.Dataset* file have to be created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26310fb7",
   "metadata": {},
   "source": [
    "First adapt directory hierarchy to fit keras  *image_dataset_from_directory* requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51492fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "breed_names = [\n",
    "    \"Abyssinian\", \"american_bulldog\", \"american_pit_bull_terrier\",\n",
    "    \"basset_hound\", \"beagle\", \"Bengal\", \"Birman\", \"Bombay\", \"boxer\",\n",
    "    \"British_Shorthair\", \"chihuahua\", \"Egyptian_Mau\", \"english_cocker_spaniel\",\n",
    "    \"english_setter\", \"german_shorthaired\", \"great_pyrenees\", \"havanese\",\n",
    "    \"japanese_chin\", \"keeshond\", \"leonberger\", \"Maine_Coon\",\n",
    "    \"miniature_pinscher\", \"newfoundland\", \"Persian\", \"pomeranian\", \"pug\",\n",
    "    \"Ragdoll\", \"Russian_Blue\", \"saint_bernard\", \"samoyed\", \"scottish_terrier\",\n",
    "    \"shiba_inu\", \"Siamese\", \"Sphynx\", \"staffordshire_bull_terrier\",\n",
    "    \"wheaten_terrier\", \"yorkshire_terrier\"\n",
    "]\n",
    "\n",
    "for breed in breed_names:\n",
    "    breed_dir = data_dir.joinpath(breed)\n",
    "    if not breed_dir.is_dir():\n",
    "        breed_dir.mkdir()\n",
    "        \n",
    "for file in data_dir.glob(\"*\"):\n",
    "    if file.suffix == '.jpg':\n",
    "        floor_pos = str(file).rfind('_')\n",
    "        new_file_path = str(file)[:floor_pos] + '\\\\' \\\n",
    "            + str(file)[floor_pos + 1:]\n",
    "        file.replace(new_file_path)     \n",
    "    elif not file.is_dir():\n",
    "        os.remove(file)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8845e",
   "metadata": {},
   "source": [
    "Define loader parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff03ba",
   "metadata": {},
   "source": [
    "Use 80% of the images for training and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=2021,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=2021,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ff945",
   "metadata": {},
   "source": [
    "## Configure the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45788a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23481066",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(breed_names))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f10d26",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06ab31e",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b180ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
